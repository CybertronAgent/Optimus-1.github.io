<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <br>
    <div class="logo" style="text-align: center;">
        <a href="index.html">
            <img src="./assets/images/optimus.jpg">
        </a>
    </div>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon ...">
    <title>Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks</title>
    <script>

    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="./static/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Optimus-1: Hybrid Multimodal Memory Empowered Agents
                            Excel in Long-Horizon Tasks</h1>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- TODO PDF Link. -->
                                <span class="link-block">
                                    <a target="_blank" href=""
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>

                                <span class="link-block">
                                    <a target="_blank" href=""
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>PDF</span>
                                    </a>
                                </span>
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a target="_blank" href="https://github.com/CybertronAgent/Optimus-1"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <div class="columns is-centered has-text-centered">
        <div class="column">
            <!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/AZeS3C_S_3M?si=lIUkwqr355KCegxV"
                title="YouTube video player" frameborder="0"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                allowfullscreen></iframe> -->
        </div>
    </div>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p style="font-size: 125%">
                            Building a general-purpose agent is a long-standing vision in the field of artificial
                            intelligence. Existing agents have made remarkable progress in many domains, yet they still
                            struggle to complete long-horizon tasks in an open world. We attribute this to the lack of
                            necessary world knowledge and experience that can guide agent through a variety of
                            long-horizon tasks. In this paper, we propose a <b>Hybrid Multimodal Memory</b> module to
                            address above challenges. It <b>1)</b>transforms knowledge into <b>Hierarchical
                                Directed Knowledge Graph</b> that allow agents to explicitly represent and learn world
                            knowledge, and <b>2) </b>summarises historical information into <b>Abstracted
                                Multimodal Experience Pool</b> that provide agents with rich references for in-context
                            learning. On top of the Hybrid Multimodal Memory module, a multimodal multimodular agent,
                            Optimus-1, is constructed with dedicated <b>Knowledge-guided Planner</b> and
                            <b>Experience-Driven Reflector</b> in Minecraft, contributing to a better planning and
                            reflection in the face of long-horizon tasks. Extensive experimental results show that
                            Optimus-1 significantly outperforms all existing agents on challenging long-horizon tasks
                            benchmark, and exhibits near human-level performance on many tasks. In addition, we
                            introduce various Multimodal Large Language Models (MLLM) as the backbone of Optimus-1, and
                            the experimental results show that Optimus-1 exhibit strong generalisation with the help of
                            Hybrid Multimodal Memory module, outperforming the GPT-4V baseline on many tasks. The
                            extensive experimental results show that Optimus-1 makes a major step towards a general
                            agent with a human-like level of performance.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <h1>Wooden</h1>
    <div class="video-section">
        <video controls>
            <source src="./assets/videos/wooden_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="./assets/videos/wooden_2.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="./assets/videos/wooden_3.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    </div>

    <h1>Stone</h1>
    <div class="video-section">
        <video controls>
            <source src="./assets/videos/stone_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="./assets/videos/stone_2.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="./assets/videos/stone_3.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    </div>

    <h1>Iron</h1>
    <div class="video-section">
        <video controls>
            <source src="./assets/videos/iron_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="./assets/videos/iron_2.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="./assets/videos/iron_3.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    </div>

    <h1>Golden</h1>
    <div class="video-section">
        <video controls>
            <source src="./assets/videos/golden_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="./assets/videos/golden_2.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="./assets/videos/golden_3.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    </div>

    <h1>Diamond</h1>
    <div class="video-section">
        <video controls>
            <source src="./assets/videos/diamond_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="./assets/videos/diamond_2.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="./assets/videos/diamond_3.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    </div>

    <h1>Armor</h1>
    <div class="video-section">
        <video controls>
            <source src="./assets/videos/armor_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="./assets/videos/armor_2.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="./assets/videos/armor_3.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    </div>

    <h1>Redstone</h1>
    <div class="video-section">
        <video controls>
            <source src="./assets/videos/redstone_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="./assets/videos/redstone_2.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    </div>


    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3">Overview framework of our Optimus-1</h2>
                        <img src="assets/images/fig2.png" class="interpolation-image" alt=""
                            style="display: block; margin-left: auto; margin-right: auto" width="600" height="700" />
                        <br>
                        <span style="font-size: 110%">
                            We divide the structure of Optimus-1 into Knowledge-Guided Planner, Experience-Driven
                            Reflector, and Action Controller. In a given game environment with a long-horizon task, the
                            Knowledge-Guided Planner senses the environment, retrieves knowledge from HDKG, and
                            decomposes the task into executable sub-goals. The action controller then sequentially
                            executes these sub-goals. During execution, the Experience-Driven Reflector is activated
                            periodically, leveraging historical experience from AMEP to assess whether Optimus-1 can
                            complete the current sub-goal. If not, it instructs the Knowledge-Guided Planner to revise
                            its plan. Through iterative interaction with the environment,Optimus-1 ultimately completes
                            the task.</span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3">Hybrid Multimodal Memory</h2>
                        <img src="assets/images/fig3.png" class="interpolation-image" alt="" width="600" height="700"
                            style="display: block; margin-left: auto; margin-right: auto" />
                        <br>
                        <span style="font-size: 110%">
                            <span style="font-weight: bold">(a)</span> Extraction process of multimodal experience. The
                            frames are filtered through video buffer and image buffer, then MineCLIP is employed to
                            compute the visual and sub-goal similarities and finally they are stored in Abstracted
                            Multimodal Experience Pool. <span style="font-weight: bold">(b)</span> Overview of
                            Hierarchical Directed Knowledge Graph. Knowledge is stored as a directed graph, where its
                            nodes represent objects, and directed edges point to materials that can be crafted by this
                            object.</span>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!-- result -->
    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Experiment</span></h2>
                        <h1><span class="dvima">Main Result of Optimus-1 on long-horizon tasks
                                benchmark. </span></h1>
                        <img src="assets/images/task.png" class="interpolation-image" alt="" width="500" height="250"
                            style="display: block; margin-left: auto; margin-right: auto" />
                        <img src="assets/images/table1.png" class="interpolation-image" alt="" width="600" height="700"
                            style="display: block; margin-left: auto; margin-right: auto" />
                        <br>
                        <span style="font-size: 110%"> We
                            report the average success rate (SR), average number of
                            steps (AS), and average time (AT) on each task group, the results of each task can be found
                            in the Appendix
                            experiment. Lower AS and AT metrics mean that the agent is more efficient at
                            completing the task, while âˆž
                            indicates that the agent is unable to complete the task. Overall represents the average
                            result on the five groups of
                            Iron, Gold, Diamond, Redstone,
                            and Armor.
                        </span>
                        <h1><span class="dvima">Ablation study results.</span></h1>
                        <img src="assets/images/table2.png" class="interpolation-image" alt="" width="300" height="700"
                            style="display: block; margin-left: auto; margin-right: auto" />
                        <br>
                        <span style="font-size: 110%"> We report average success rate (SR) on
                            each task group. P., R., K.,E. represent Planning, Reflection, Knowledge, and Experience,
                            respectively.
                        </span>

                        <h1><span class="dvima">Ablation study on AMEP.</span></h1>
                        <img src="assets/images/table3.png" class="interpolation-image" alt="" width="300" height="700"
                            style="display: block; margin-left: auto; margin-right: auto" />
                        <br>
                        <span style="font-size: 110%"> We report the average success rate (SR) on
                            each task group. Zero, Suc., and
                            Fail. represent retrieving from AMEP without getting the case, getting the success case, and
                            getting the
                            failure case, respectively.
                        </span>

                        <h1><span class="dvima">Generalisation and Self-Evoluation</span></h1>
                        <div class="image-container">
                            <div class="image-wrapper">
                                <img src="assets/images/fig5-1-1.png" alt="" width="500" height="300"
                                    style="margin-left: auto; margin-right: auto" />
                                <img src="assets/images/fig5-2-1.png" alt="" width="500" height="300"
                                    style="margin-left: auto; margin-right: auto" />

                            </div>
                        </div>

                        <br>
                        <span style="font-size: 110%">(a) With the help of Hybrid Multimodal Memory, various
                            MLLM-based
                            Optimus-1 have demonstrated 2 to 6 times performance
                            improvement. (b) Illustration of the change in Optimus-1 success rate on the unseen
                            task over 4 epochs.
                        </span>
                    </div>
                </div>

            </div>
        </div>
    </section>

    <!--Conclusion-->
    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Conclusion</span></h2>

                        <p style="font-size: 125%">
                            In this paper, we propose Hybrid Multimodal Memory module, which is inspired by the major
                            influence of the human long-term memory system on the completion of long-horizon tasks.
                            Hybrid Multimodal Memory module consists of two parts: HDKG and AMEP. HDKG provides the
                            necessary world knowledge for the planning phase of the agent, and AMEP provides the refined
                            historical experience for the reflection phase of the agent. On top of the Hybrid Multimodal
                            Memory, we construct the multimodal and multimodular agent Optimus-1 in Minecraft. Extensive
                            experimental results show that Optimus-1 outperforms all existing agents on long-horizon
                            tasks. Furthermore, we validate that general-purpose MLLM, based on our proposed Hybrid
                            Multimodal Memory and without additional parameter updates, can exceed the powerful GPT-4V
                            baseline. This self-evolution approach provides novel insights and directions for the study
                            of general-purpose agents.
                        </p>

                    </div>
                </div>

            </div>
        </div>
    </section>


</body>

</html>